{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost version:  1.5.0-dev\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div style=\"\n",
       "                    width: 24px;\n",
       "                    height: 24px;\n",
       "                    background-color: #e1e1e1;\n",
       "                    border: 3px solid #9D9D9D;\n",
       "                    border-radius: 5px;\n",
       "                    position: absolute;\"> </div>\n",
       "                <div style=\"margin-left: 48px;\">\n",
       "                    <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "                    <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-90468ec6-73e9-11ec-965d-a87eeae84103</p>\n",
       "                    <table style=\"width: 100%; text-align: left;\">\n",
       "                    \n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "                    <td style=\"text-align: left;\"><strong>Cluster type:</strong> LocalCluster</td>\n",
       "                </tr>\n",
       "                \n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard: </strong>\n",
       "                        <a href=\"http://127.0.0.1:8787/status\">http://127.0.0.1:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\"></td>\n",
       "                </tr>\n",
       "                \n",
       "                    </table>\n",
       "                    \n",
       "                <details>\n",
       "                <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "                \n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "                <div style=\"\n",
       "                    width: 24px;\n",
       "                    height: 24px;\n",
       "                    background-color: #e1e1e1;\n",
       "                    border: 3px solid #9D9D9D;\n",
       "                    border-radius: 5px;\n",
       "                    position: absolute;\"> </div>\n",
       "                <div style=\"margin-left: 48px;\">\n",
       "                    <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "                    <p style=\"color: #9D9D9D; margin-bottom: 0px;\">5481872f</p>\n",
       "                    <table style=\"width: 100%; text-align: left;\">\n",
       "                    \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "                <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"><strong>Workers:</strong> 1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong>\n",
       "                    8\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong>\n",
       "                    251.65 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "                    </table>\n",
       "                    <details>\n",
       "                    <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "                    \n",
       "        <div style=\"\">\n",
       "            \n",
       "            <div>\n",
       "                <div style=\"\n",
       "                    width: 24px;\n",
       "                    height: 24px;\n",
       "                    background-color: #FFF7E5;\n",
       "                    border: 3px solid #FF6132;\n",
       "                    border-radius: 5px;\n",
       "                    position: absolute;\"> </div>\n",
       "                <div style=\"margin-left: 48px;\">\n",
       "                    <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "                    <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-bd5745ba-5d01-4bba-8252-09ae0443b644</p>\n",
       "                    <table style=\"width: 100%; text-align: left;\">\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\"><strong>Comm:</strong> tcp://127.0.0.1:44487</td>\n",
       "                            <td style=\"text-align: left;\"><strong>Workers:</strong> 1</td>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\">http://127.0.0.1:8787/status</a>\n",
       "                            </td>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Total threads:</strong>\n",
       "                                8\n",
       "                            </td>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Started:</strong>\n",
       "                                Just now\n",
       "                            </td>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Total memory:</strong>\n",
       "                                251.65 GiB\n",
       "                            </td>\n",
       "                        </tr>\n",
       "                    </table>\n",
       "                </div>\n",
       "            </div>\n",
       "        \n",
       "            <details style=\"margin-left: 48px;\">\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Workers</h3></summary>\n",
       "            \n",
       "            <div style=\"margin-bottom: 20px;\">\n",
       "                <div style=\"width: 24px;\n",
       "                            height: 24px;\n",
       "                            background-color: #DBF5FF;\n",
       "                            border: 3px solid #4CC9FF;\n",
       "                            border-radius: 5px;\n",
       "                            position: absolute;\"> </div>\n",
       "                <div style=\"margin-left: 48px;\">\n",
       "                <details>\n",
       "                    <summary>\n",
       "                        <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                    </summary>\n",
       "                    <table style=\"width: 100%; text-align: left;\">\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\"><strong>Comm: </strong> tcp://127.0.0.1:37321</td>\n",
       "                            <td style=\"text-align: left;\"><strong>Total threads: </strong> 8</td>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Dashboard: </strong>\n",
       "                                <a href=\"http://127.0.0.1:33155/status\">http://127.0.0.1:33155/status</a>\n",
       "                            </td>\n",
       "                            <td style=\"text-align: left;\">\n",
       "                                <strong>Memory: </strong>\n",
       "                                251.65 GiB\n",
       "                            </td>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style=\"text-align: left;\"><strong>Nanny: </strong> tcp://127.0.0.1:34445</td>\n",
       "                            <td style=\"text-align: left;\"></td>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                                <strong>Local directory: </strong>\n",
       "                                /home/btong/github/data-science-blueprints/churn/dask-worker-space/worker-tikamitf\n",
       "                            </td>\n",
       "                        </tr>\n",
       "                        \n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>GPU: </strong>Quadro RTX 8000\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>GPU memory: </strong>\n",
       "                        47.46 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "                \n",
       "                        \n",
       "                    </table>\n",
       "                </details>\n",
       "                </div>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        </div>\n",
       "        \n",
       "                    </details>\n",
       "                </div>\n",
       "            </div>\n",
       "        \n",
       "                </details>\n",
       "                \n",
       "                </div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:44487' processes=1 threads=8, memory=251.65 GiB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "from time import time\n",
    "from functools import reduce\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, wait, progress, get_worker\n",
    "from datetime import datetime\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost.dask import DaskDMatrix\n",
    "\n",
    "# Notebook to python script conversion: set run_as_script=True. May want to clear all notebook outputs first, then save.\n",
    "# Run this in CLI: jupyter nbconvert --to=script python_telco_data_ENC_ML_hdfs.ipynb --output=do-ml_gscv\n",
    "run_as_script = False # If true, need to MANUALLY wrap converted script in \"if __name__ == '__main__':\" to resolve dask issues with multiprocess.\n",
    "\n",
    "\n",
    "start_time_str = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "# Vars to change when running on internal clusters (e.g. spark1, spark2a). Other params such as hdfs and dask hosts are preconfigured.\n",
    "# run_type, cluster_type, data_format, etl_output_dir, enc_output_dir\n",
    "# Example local run: ./do-ml.py --run_type=gpu\n",
    "# Example cluster run: ./do-ml.py --run_type=cpu --cluster_type=spark1 --data_format=parquet --etl_output_dir=/data/erife-output/churn/10k/gpu/churn-etl.parquet --enc_output_dir=/data/erife-output/churn/churn-encoded\n",
    "\n",
    "# etl_num_parts = 4 # Used for local testing of physical data partitioning only\n",
    "default_run_type = 'gpu'\n",
    "default_enable_gridSearchCV = True # Run gridSearchCV for HPO.\n",
    "default_cv_strategy = 'node' # Select 'node' or 'cluster'. Node trains each fold independently at all grid points. Cluster schedules everything at once.\n",
    "default_data_format = 'parquet'\n",
    "\n",
    "# Default data dirs assumes local run. \n",
    "# Use ABSOLUTE directories for enc_output_dir since externally started dask cluster cannot resolve relative dirs.\n",
    "# default_etl_output_dir = '/data/telco_churn/etl_data/sf1k_' + default_data_format # CHANGE ME\n",
    "# default_enc_output_dir = '/data/telco_churn/enc_data' # WARNING: Directory will be wiped with each run.\n",
    "default_etl_output_dir = './churn-etl.parquet' # CHANGE ME\n",
    "default_enc_output_dir = './enc_data' # WARNING: Directory will be wiped with each run.\n",
    "\n",
    "default_hdfs_host = 'localhost' # Also default_dask_host\n",
    "default_hadoop_home = os.environ.get('HADOOP_HOME')\n",
    "default_java_home = os.environ.get('JAVA_HOME')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--run_type', help='Run type (default=\"%s\").' % default_run_type, default=default_run_type)\n",
    "parser.add_argument('--enable_gridSearchCV', help='Run GridSearchCV (default=\"%s\").' % default_enable_gridSearchCV, default=default_enable_gridSearchCV)\n",
    "parser.add_argument('--cv_strategy', help='Run type (default=\"%s\").' % default_cv_strategy, default=default_cv_strategy)\n",
    "parser.add_argument('--num_folds', help='Number of folds for cross-validation.', default=8, type=int)\n",
    "parser.add_argument('--cuda_visible_devices', help='CUDA_VISIBLE_DEVICES for multi-GPU configs (default=\"0\").', default='0')\n",
    "parser.add_argument('--data_format', help='Data source format (default=\"%s).' % default_data_format, default=default_data_format)\n",
    "parser.add_argument('--storage_backend', help='Data storage backend. Select \"local\" or \"hdfs\" (default=\"local\").', default='local')\n",
    "parser.add_argument('--cluster_type', help='Dask cluster type. Select \"local\", \"spark1\", \"spark2a\" (default=\"local\").', default='local')\n",
    "parser.add_argument('--etl_output_dir', help='ETL data output directory \"%s\".' % default_etl_output_dir, default=default_etl_output_dir)\n",
    "parser.add_argument('--enc_output_dir', help='Encoded data output directory \"%s\".' % default_enc_output_dir, default=default_enc_output_dir)\n",
    "parser.add_argument('--hdfs_host', help='HDFS namenode (default=\"localhost\").', default=default_hdfs_host)\n",
    "parser.add_argument('--hdfs_port', help='HDFS namenode port (default=9000).', default=9000, type=int)\n",
    "parser.add_argument('--dask_host', help='Dask host (default=hdfs_host).', default=default_hdfs_host)\n",
    "parser.add_argument('--dask_port', help='Dask scheduler port (default=8786).', default=8786, type=int)\n",
    "\n",
    "parser.add_argument('--hadoop_home', help='Hadoop home directory (default=\"%s\").' % default_hadoop_home, default=default_hadoop_home)\n",
    "parser.add_argument('--java_home', help='Java home directory (default=\"%s\").' % default_java_home, default=default_java_home)\n",
    "\n",
    "parser.add_argument('--enc_num_row_groups', help='Encoded data parquet file num_row_groups (default=8).', default=8, type=int)\n",
    "parser.add_argument('--max_depth', help='xgboost max_depth param (default=10).', default=10, type=int)\n",
    "parser.add_argument('--num_boost_round', help='xgboost num_boost_round param (default=200).', default=200, type=int)\n",
    "parser.add_argument('--score_metric', help='Scoring metric for inferencing (default=acc).', default='auc')\n",
    "\n",
    "\n",
    "if run_as_script == True:\n",
    "    args = parser.parse_args()\n",
    "else:\n",
    "    # Run within notebook. Passing empty string allows argparse to work within jupyter notebook.\n",
    "    args = parser.parse_args([])\n",
    "    \n",
    "# Run settings:\n",
    "run_type = args.run_type # Select cpu/gpu\n",
    "enable_gridSearchCV = args.enable_gridSearchCV\n",
    "cv_strategy = args.cv_strategy\n",
    "num_folds = args.num_folds\n",
    "cuda_visible_devices = args.cuda_visible_devices\n",
    "data_format = args.data_format # csv or parquet\n",
    "storage_backend = args.storage_backend # 'local' or 'hdfs'\n",
    "cluster_type = args.cluster_type # local\n",
    "\n",
    "# Data dirs:\n",
    "etl_output_dir = args.etl_output_dir\n",
    "enc_output_dir = args.enc_output_dir\n",
    "\n",
    "# Parameters for encoding ETL data and outputting to parquet:\n",
    "enc_num_row_groups = args.enc_num_row_groups\n",
    "\n",
    "# HDFS settings:\n",
    "hdfs_host = args.hdfs_host\n",
    "hdfs_port = args.hdfs_port\n",
    "\n",
    "# Dask settings:\n",
    "dask_host = args.dask_host\n",
    "dask_port = args.dask_port\n",
    "\n",
    "# Env settings:\n",
    "hadoop_home = args.hadoop_home\n",
    "java_home = args.java_home\n",
    "\n",
    "# xgboost params:\n",
    "max_depth = args.max_depth\n",
    "num_boost_round = args.num_boost_round\n",
    "score_metric = args.score_metric\n",
    "\n",
    "\n",
    "def setenv():\n",
    "    \"\"\"\n",
    "    Function to be ran on dask cluster to overide env vars.\n",
    "    Example: client.run(setenv)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    \n",
    "    # Need env configured on all workers for ARROW_LIBHDFS_DIR so that pyarrow HDFS can be used.\n",
    "    # https://stackoverflow.com/questions/55922487/what-could-be-the-explaination-of-this-pyarrow-lib-arrowioerror-hdfs-file-does\n",
    "    classpath = subprocess.Popen([hadoop_home+\"/bin/hdfs\", \"classpath\", \"--glob\"], stdout=subprocess.PIPE).communicate()[0]\n",
    "    \n",
    "    os.environ[\"HADOOP_HOME\"] = hadoop_home\n",
    "    os.environ[\"JAVA_HOME\"] = java_home\n",
    "    os.environ[\"CLASSPATH\"] = classpath.decode(\"utf-8\")\n",
    "    os.environ[\"ARROW_LIBHDFS_DIR\"] = hadoop_home+\"/lib/native\"\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_visible_devices\n",
    "\n",
    "\n",
    "if cluster_type == 'local':\n",
    "    if run_type == 'gpu':\n",
    "        from dask_cuda import LocalCUDACluster\n",
    "\n",
    "#         # LocalCUDACluster for multi-GPU on same node:\n",
    "# #         cuda_cluster = LocalCUDACluster() #n_workers=1, threads_per_worker=8) # p3.2xlarge has 1x V100, 8 vCPU\n",
    "#         cuda_cluster = LocalCUDACluster(n_workers=2, threads_per_worker=8) # p3.8xlarge has 4x V100, 32 vCPU\n",
    "#         client = Client(cuda_cluster)\n",
    "    \n",
    "        # Something broke in localCUDACluster. Start dask-scheduler and dask-cuda-worker manually. Then connect to endpoint.\n",
    "        client = Client(n_workers=1, threads_per_worker=8)\n",
    "#         client = Client('tcp://127.0.0.1:8786')\n",
    "    else:\n",
    "        # xgboost training seems to benefit from fewer workers and more threads. Same with inference against entire directory. \n",
    "        # Set n_workers equal to number of physical machines.\n",
    "#         client = Client(n_workers=2, threads_per_worker=30)\n",
    "        client = Client(n_workers=1, threads_per_worker=32)\n",
    "    \n",
    "elif cluster_type == 'spark1':\n",
    "    storage_backend = 'hdfs'\n",
    "    hdfs_host = '10.150.162.36'\n",
    "    dask_host_str = 'tcp://'+hdfs_host+':8786'\n",
    "    hadoop_home = '/opt/hadoop-3.2.1'\n",
    "    java_home = '/usr/lib/jvm/java-1.8.0-openjdk-amd64'\n",
    "    cuda_visible_devices = \"0,1\"\n",
    "    \n",
    "    client = Client(dask_host_str)\n",
    "    client.run(setenv) # Apply env settings on entire dask cluster\n",
    "    \n",
    "elif cluster_type == 'spark2a':\n",
    "    storage_backend = 'hdfs'\n",
    "    hdfs_host = '10.150.166.218'\n",
    "    dask_host_str = 'tcp://'+hdfs_host+':8786'\n",
    "    hadoop_home = '/opt/hadoop/hadoop-3.2.1'\n",
    "    java_home = '/usr/lib/jvm/java-1.8.0-openjdk-amd64'\n",
    "    cuda_visible_devices = \"0,1\"\n",
    "    \n",
    "    client = Client(dask_host_str)\n",
    "    client.run(setenv) # Apply env settings on entire dask cluster\n",
    "#     client = Client('tcp://127.0.0.1:8786') # localhost\n",
    "#     client = Client(n_workers=6, threads_per_worker=20) # overide\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Choose cluster_type as \"local\", \"spark1\", \"spark2a\".')\n",
    "    \n",
    "print('xgboost version: ', xgb.__version__)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b0de4470-4881-4507-929e-4e92190af870",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if storage_backend == 'local':\n",
    "    etl_files = glob.glob(etl_output_dir+'/*.'+data_format) # ETL data directory (to be encoded)\n",
    "    \n",
    "elif storage_backend == 'hdfs':\n",
    "    hdfs = pa.hdfs.connect(hdfs_host, hdfs_port)\n",
    "    hdfs_con_str = 'hdfs://'+hdfs_host+':'+str(hdfs_port)\n",
    "    \n",
    "    # Assumes ETL data already on hdfs:\n",
    "    etl_output_dir = hdfs_con_str + etl_output_dir\n",
    "    enc_output_dir = hdfs_con_str + enc_output_dir\n",
    "#     xgb_hdfs_output_dir = hdfs_con_str + '/data/erife-output/churn/xgb_models' # Output directory for xgboost model file. Use None for no output.\n",
    "    xgb_hdfs_output_dir = None\n",
    "    \n",
    "    # Issue with xgboost .save_model() when writing out to hdfs. Requires compiling xgboost with hdfs feature enabled. Write locally and store backup on hdfs.\n",
    "    \n",
    "    etl_files = hdfs.ls(etl_output_dir[len(hdfs_con_str):]) # ETL data directory (to be encoded)\n",
    "    etl_files = [hdfs_con_str+fn for fn in etl_files if fn.split('.')[-1]==data_format]\n",
    "    \n",
    "    print('Number of '+data_format+' found in ETL folder:', len(etl_files))\n",
    "\n",
    "\n",
    "# xgboost params:\n",
    "xgb_params = { \n",
    "    'random_state': 0,\n",
    "    'eta': 0.1,\n",
    "    'gamma': 0.1,\n",
    "    'max_depth': max_depth, \n",
    "#     'num_boost_round': num_boost_round, # Number of boosting rounds: num_boost_round in xgboost, numRound in xgboost4j, n_estimators in scikit-learn.\n",
    "    'max_leaves': 4*256,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc', # Applied to eval_set/test_data if provided\n",
    "    'booster': 'gbtree',\n",
    "}\n",
    "\n",
    "if run_type == 'cpu':\n",
    "    tree_method = 'hist'\n",
    "elif run_type == 'gpu':   \n",
    "    tree_method = 'gpu_hist'\n",
    "\n",
    "xgb_params['tree_method'] = tree_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load JSON with Schema for ETL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to one-hot-encode: ['MultipleLines', 'OnlineBackup', 'InternetService', 'OnlineSecurity', 'Contract', 'PaymentMethod', 'StreamingMovies', 'StreamingTV', 'TechSupport', 'DeviceProtection']\n",
      "Binary categorical columns: ['PaperlessBilling', 'Partner', 'gender', 'Dependents', 'PhoneService']\n",
      "Numeric columns: ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
      "\n",
      "Number of columns after encoding:  42\n"
     ]
    }
   ],
   "source": [
    "with open('churn_etl_schema.json') as json_file: \n",
    "    schema_json = json.load(json_file)\n",
    "\n",
    "label_col = 'Churn' # Needs to be numeric encoded (i.e., with StringIndexer)\n",
    "\n",
    "cat_str_cols = list(schema_json['categorical'].keys())\n",
    "num_cols = schema_json['numeric']\n",
    "ignore_cols = schema_json['unique']\n",
    "\n",
    "all_cols = cat_str_cols + num_cols + ignore_cols\n",
    "\n",
    "# Determine categorical binary cols which need to be label encoded:\n",
    "binary_cols = [cat for cat in schema_json['categorical'] if len(schema_json['categorical'][cat])==2]\n",
    "\n",
    "# One hot encode only non-binary, categorical columns:\n",
    "ohe_cols = [cc for cc in cat_str_cols if cc not in binary_cols] # Preserve order\n",
    "\n",
    "print('Columns to one-hot-encode:', ohe_cols)\n",
    "print('Binary categorical columns:', binary_cols)\n",
    "print('Numeric columns:', num_cols)\n",
    "\n",
    "# TODO: low cardinality numeric cols. These may require one-hot-encoding.\n",
    "\n",
    "# Get unique categories for binary and one-hot columns. Set alphabetical with explicit order to be used as global index.\n",
    "cat_index_codes = {cc: CategoricalDtype(sorted(schema_json['categorical'][cc]), ordered=True) for cc in cat_str_cols}\n",
    "\n",
    "# Generate column names with prefixes:\n",
    "dummy_cols = [name+'_'+val for name in ohe_cols for val in schema_json['categorical'][name]]\n",
    "\n",
    "# Update column labels:\n",
    "dummy_cols = [re.sub('[()]', '', cc.replace(' ', '-')) for cc in dummy_cols]\n",
    "all_enc_cols = num_cols + binary_cols + dummy_cols + ['cv_idx']\n",
    "\n",
    "# print('All encoded output columns:', all_enc_cols)\n",
    "print()\n",
    "print('Number of columns after encoding: ', len(all_enc_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of column combinations 6\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering via taking combinations of top few feature categorical columns:\n",
    "from itertools import combinations\n",
    "\n",
    "combo_cols = ['Contract', 'OnlineSecurity', 'InternetService', 'PaymentMethod'] # Top categorical features identified by SHAP\n",
    "# combo_cols = ['SeniorCitizen'] + ohe_cols + binary_cols # Take all columns\n",
    "\n",
    "combo_pairs = list(combinations(combo_cols, 2))\n",
    "print('Number of column combinations', len(combo_pairs))\n",
    "\n",
    "# Combine pairs of columns, categorize, then OHE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 41555 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata generation time:  2.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID_src</th>\n",
       "      <th>train_set</th>\n",
       "      <th>cv_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>7838-LAZFO</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>8189-DUKMV</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>3758-CKOQL</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>5619-PTMIK</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>9115-YQHGA</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>6960-HVYXR</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>4676-WLUHT</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>2403-BCASL</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>3722-WPXTK</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6560</th>\n",
       "      <td>3896-RCYYE</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7032 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customerID_src  train_set  cv_idx\n",
       "2188     7838-LAZFO       True       0\n",
       "2287     8189-DUKMV       True       1\n",
       "1066     3758-CKOQL       True       2\n",
       "1594     5619-PTMIK       True       3\n",
       "2528     9115-YQHGA      False       4\n",
       "...             ...        ...     ...\n",
       "6623     6960-HVYXR       True       3\n",
       "3527     4676-WLUHT      False       4\n",
       "657      2403-BCASL      False       5\n",
       "5669     3722-WPXTK      False       6\n",
       "6560     3896-RCYYE       True       7\n",
       "\n",
       "[7032 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def telco_metadata_ttsplitter(data_path, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Generate metadata for original customerID in telco churn data. Use metadata to construct stratified train_test_split with less leakage.\n",
    "    \"\"\"\n",
    "    with Client(n_workers=8, threads_per_worker=1) as client_local:\n",
    "        # Read subset of columns needed to perform train/test split based on original customer source:\n",
    "        df_etl = dd.read_parquet(data_path, columns=['customerID', label_col]) #.persist()\n",
    "\n",
    "        # Truncate customerID to obtain original customer info:\n",
    "        df_etl['customerID_src'] = df_etl['customerID'].str[:10]\n",
    "\n",
    "        # Stratified split requires information in Churn column. Select first replica in each unique customerID_src group.\n",
    "        df_etl_uniq = df_etl[['customerID_src', label_col]].groupby('customerID_src').first()\n",
    "        df_etl_uniq = df_etl_uniq[[label_col]].reset_index()\n",
    "        df_etl_uniq = df_etl_uniq.sort_values('customerID_src') # Ensure consistent ordering before running train_test_split()\n",
    "        df_etl_uniq = df_etl_uniq.compute()\n",
    "\n",
    "    # Can get rid of a lot of code by going directly to source csv file. \n",
    "\n",
    "    # Use sklearn train_test_split() to stratify and split keys:\n",
    "    strat_train_idx, strat_test_idx = train_test_split(range(len(df_etl_uniq)), test_size=test_size, stratify=df_etl_uniq[label_col].values, random_state=42)\n",
    "    df_etl_uniq['train_set'] = False\n",
    "    df_etl_uniq.loc[strat_train_idx, 'train_set'] = True\n",
    "    df_etl_uniq = df_etl_uniq.drop(columns=label_col)\n",
    "    return(df_etl_uniq)\n",
    "\n",
    "tic = time()\n",
    "test_size = 0.2 # Fraction of data used in test set within train_test_split()\n",
    "tt_split_toc = telco_metadata_ttsplitter(etl_output_dir, test_size)\n",
    "tt_split_toc = tt_split_toc.sample(frac=1, random_state=0) # Shuffle rows to ensure data well mixed.\n",
    "tt_split_toc['cv_idx'] = np.mod(np.arange(len(tt_split_toc)), num_folds) # Assign fold indices for cross-validation\n",
    "print('Metadata generation time: ', str(np.round(time()-tic,2)) + 's')\n",
    "tt_split_toc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read ETL'd Files and Output Encoded Data to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btong/miniconda3/envs/rapids-dev/lib/python3.8/site-packages/distributed/node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 40585 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data encoding took: 2.45s\n",
      "Number of input records from ETL files: 703200\n",
      "  Encoded records in train set: 562500\n",
      "  Encoded records in test set: 140700\n",
      "Number of records removed during encoding: 0\n"
     ]
    }
   ],
   "source": [
    "def naive_ohe_enc_parts(run_type, data_path, ohe_cols, binary_cols, cat_index_codes, drop_cols=None, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Data encoding pipeline using pandas, operating on dictionary encoded parquet files. Updated to handle global categories.\n",
    "    \n",
    "    run_type: str\n",
    "        Select 'cpu' or 'gpu' as hardware for running.\n",
    "    data_path: str\n",
    "        Location of parquet files (either directory or filename).\n",
    "    split_data: bool\n",
    "        Split data into train/test set.\n",
    "    ohe_cols: list\n",
    "        List of strings with categorical columns to be one-hot-encoded.\n",
    "    binary_cols: list\n",
    "        List of strings with binary categorical columns to encode. \n",
    "    cat_index_codes: dictionary of CategoricalDtype\n",
    "        Global mapping of ordered classes in each categorical column.\n",
    "    drop_cols: list\n",
    "        List of strings with columns to drop.\n",
    "    test_size: float between [0,1]\n",
    "        Split data into train/test set.\n",
    "    \"\"\"\n",
    "    if run_type == 'gpu':\n",
    "        import cudf as hw\n",
    "    elif run_type == 'cpu':\n",
    "        import pandas as hw\n",
    "    else:\n",
    "        raise ValueError('Select cpu or gpu. Case not handled.')\n",
    "    \n",
    "    if data_format == 'parquet':\n",
    "        data_pd = hw.read_parquet(data_path, read_dictionary=binary_cols+ohe_cols)\n",
    "    elif data_format == 'csv':\n",
    "        data_pd = hw.read_csv(data_path, dtype=cat_index_codes) # Apply global categories\n",
    "        \n",
    "    data_pd = data_pd.dropna() # Make sure data doesn't contain NA's\n",
    "    \n",
    "    # Merge table with training metadata for subsequent train/test split:\n",
    "    data_pd['customerID_src'] = data_pd['customerID'].str[:10]\n",
    "    data_pd = data_pd.merge(tt_split_toc[['customerID_src', 'train_set', 'cv_idx']], on='customerID_src', how='left')\n",
    "    \n",
    "    if drop_cols != None:\n",
    "        data_pd.drop(columns=drop_cols, inplace=True)\n",
    "    \n",
    "    if data_format == 'parquet':\n",
    "        # Update categorical dictionary to global values:\n",
    "        for cc in binary_cols+ohe_cols:\n",
    "    #         data_pd[cc].cat.set_categories(list(cat_index_codes[cc].categories), ordered=True, inplace=True) # Works in pandas, but not cudf\n",
    "            data_pd[cc] = data_pd[cc].astype(cat_index_codes[cc]) # Works in pandas, but not cudf\n",
    "        \n",
    "    # One hot encoding of categorical columns (3+ categories):\n",
    "    data_pd_enc = hw.get_dummies(data_pd, columns=ohe_cols, drop_first=False, dtype='bool')\n",
    "    \n",
    "    # Binary encode columns (e.g., [Female, Male], [False, True], or [No, Yes] => [0, 1]):\n",
    "    for cc in binary_cols:\n",
    "        data_pd_enc[cc] = data_pd_enc[cc].cat.codes.astype('bool')\n",
    "        \n",
    "    # Convert uint8 to int8 for Spark compatibility.\n",
    "    uint8_cols = data_pd_enc.select_dtypes('uint8').columns\n",
    "    data_pd_enc[uint8_cols] = data_pd_enc[uint8_cols].astype('int8')\n",
    "    \n",
    "    # Replace special characters in column name:\n",
    "    data_pd_enc.columns = [re.sub('[()]', '', cc.replace(' ', '-')) for cc in data_pd_enc.columns]\n",
    "    return(data_pd_enc)\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def enc_and_write_pq(fn):\n",
    "    enc_naive_pd = naive_ohe_enc_parts('cpu', fn, ohe_cols, binary_cols, cat_index_codes, drop_cols='customerID', test_size=test_size)\n",
    "#     enc_naive_pd[['MonthlyCharges', 'TotalCharges']] = enc_naive_pd[['MonthlyCharges', 'TotalCharges']].astype('float32')\n",
    "    \n",
    "    row_group_size=np.ceil(len(enc_naive_pd)/enc_num_row_groups)\n",
    "    # Dask might be assembling cols based on order of completion. Rearrange columns prior to writing output for consistency!\n",
    "    \n",
    "    \n",
    "    if test_size == 0:\n",
    "        # All data passed into training:\n",
    "        enc_naive_pd = enc_naive_pd[all_enc_cols]\n",
    "        enc_naive_pd.to_parquet(os.path.join(enc_output_dir+'/train', fn.split('/')[-1].replace('.csv', '.parquet')), flavor='spark', row_group_size=row_group_size)\n",
    "    else:\n",
    "        enc_naive_pd_grp = enc_naive_pd.groupby('train_set')\n",
    "        \n",
    "        train_df = enc_naive_pd_grp.get_group(True)\n",
    "        train_df[all_enc_cols].to_parquet(os.path.join(enc_output_dir+'/train', fn.split('/')[-1].replace('.csv', '.parquet')), flavor='spark', row_group_size=row_group_size)\n",
    "\n",
    "        test_df = enc_naive_pd_grp.get_group(False)\n",
    "        test_df[all_enc_cols].to_parquet(os.path.join(enc_output_dir+'/test', fn.split('/')[-1].replace('.csv', '.parquet')), flavor='spark', row_group_size=row_group_size)\n",
    "    return(fn)\n",
    "\n",
    "\n",
    "# Wipe contents of enc_output_dir:\n",
    "if storage_backend == 'hdfs':\n",
    "    try:\n",
    "        hdfs.delete(enc_output_dir[len(hdfs_con_str):], recursive=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    hdfs.mkdir(enc_output_dir[len(hdfs_con_str):])\n",
    "    hdfs.mkdir(enc_output_dir[len(hdfs_con_str):]+'/train')\n",
    "    hdfs.mkdir(enc_output_dir[len(hdfs_con_str):]+'/test')\n",
    "        \n",
    "elif storage_backend == 'local':\n",
    "    try:\n",
    "        # RECURSIVELY DELETE DIRECTORY and then add it\n",
    "        shutil.rmtree(enc_output_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    os.mkdir(enc_output_dir)\n",
    "    os.mkdir(enc_output_dir+'/train')\n",
    "    os.mkdir(enc_output_dir+'/test')\n",
    "\n",
    "\n",
    "# Create local dask client to perform encoding. GPU run near memory limit so needed to use nthreads=1 in primary dask cluster.\n",
    "tic = time()\n",
    "with Client(n_workers=8, threads_per_worker=1) as client_local:\n",
    "    out = [enc_and_write_pq(fn) for fn in etl_files]\n",
    "    dask.compute(out, scheduler=client_local)\n",
    "t_encode = time() - tic\n",
    "\n",
    "print('Data encoding took:', '{:0.2f}'.format(t_encode) + 's')\n",
    "\n",
    "if data_format == 'parquet':\n",
    "    etl_num_recs = len(dd.read_parquet(etl_output_dir))\n",
    "    enc_train_num_recs = len(dd.read_parquet(enc_output_dir+'/train'))\n",
    "    enc_test_num_recs = len(dd.read_parquet(enc_output_dir+'/test'))\n",
    "    diff_num_recs = etl_num_recs - enc_train_num_recs - enc_test_num_recs\n",
    "    print('Number of input records from ETL files:', etl_num_recs)\n",
    "    print('  Encoded records in train set:', enc_train_num_recs)\n",
    "    print('  Encoded records in test set:', enc_test_num_recs)\n",
    "    print('Number of records removed during encoding:', diff_num_recs)\n",
    "    \n",
    "    if diff_num_recs != 0:\n",
    "        raise ValueError('Different number of records between ETL input and ENC output detected.')\n",
    "        \n",
    "    # TODO: add fast line counter for csv without having to read entire file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Encoded Data and Run ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting xgboost gpu training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:52:46] task [xgboost.dask]:tcp://127.0.0.1:37321 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_load_time': 4.55, 'train_model_time': 5.01, 'export_model_time': 0.08, 'total_time': 10.778921604156494}\n",
      "Dask xgboost gpu training time: 10.78s\n"
     ]
    }
   ],
   "source": [
    "def dask_xgb_train_from_enc(client, run_type, data_path, label_col, xgb_params, xgb_model_name):\n",
    "    \"\"\"\n",
    "    Use dask + xgboost for training against already encoded data.\n",
    "    \"\"\"\n",
    "    if run_type == 'cpu':\n",
    "        ddf_enc = dd.read_parquet(data_path)\n",
    "    elif run_type == 'gpu':\n",
    "        import dask_cudf\n",
    "        import cupy as cp\n",
    "        ddf_enc = dask_cudf.read_parquet(data_path)\n",
    "    else:\n",
    "        raise ValueError('Select run_type of cpu or gpu.')\n",
    "    \n",
    "    tic = time()\n",
    "    ddf_enc = client.persist(ddf_enc)\n",
    "    wait([ddf_enc])\n",
    "    \n",
    "    feature_cols = [cc for cc in ddf_enc.columns if cc not in [label_col, 'cv_idx']]\n",
    "    X = ddf_enc[feature_cols].astype('float32')\n",
    "    y = ddf_enc[label_col].astype('float32')\n",
    "    \n",
    "#     # Persist data:\n",
    "#     X = client.persist(X)\n",
    "#     y = client.persist(y)\n",
    "#     wait([X, y])\n",
    "    \n",
    "    # Use XGBOOST API:\n",
    "    if run_type == 'gpu':\n",
    "        # See example: https://github.com/dmlc/xgboost/blob/master/demo/dask/gpu_training.py\n",
    "        # `DaskDeviceQuantileDMatrix` is used instead of `DaskDMatrix`, be careful\n",
    "        # that it can not be used for anything else than training.\n",
    "        dtrain = xgb.dask.DaskDeviceQuantileDMatrix(client, X, y)\n",
    "    else:\n",
    "        dtrain = DaskDMatrix(client, X, y)\n",
    "    \n",
    "    del ddf_enc, X, y # Cleanup\n",
    "    data_load_time = np.round(time() - tic, 2)\n",
    "    \n",
    "    tic = time()\n",
    "    xgb_model = xgb.dask.train(client, xgb_params, dtrain, num_boost_round=num_boost_round)['booster']\n",
    "    train_model_time = np.round(time() - tic, 2)\n",
    "    \n",
    "    # Save xgb model to disk:\n",
    "    tic = time()\n",
    "    xgb_model.save_model(xgb_model_name+'.model') # Save model to current dir\n",
    "    xgb_model.save_model('/tmp/'+xgb_model_name+'.json') # Experimental JSON format. To be nested in output file with timings/metrics.\n",
    "    \n",
    "    # Move local xgb-model to hdfs if xgb_hdfs_output_dir specified:\n",
    "    if (storage_backend == 'hdfs'):\n",
    "        if xgb_hdfs_output_dir != None:\n",
    "            with open(xgb_model_name+'.model','rb') as f:\n",
    "                hdfs.upload(os.path.join(xgb_hdfs_output_dir, xgb_model_name+'.model'), f)\n",
    "    export_model_time = np.round(time() - tic, 2)\n",
    "    \n",
    "    metrics = {\n",
    "        'data_load_time': data_load_time,\n",
    "        'train_model_time': train_model_time,\n",
    "        'export_model_time': export_model_time\n",
    "        }\n",
    "    \n",
    "    del dtrain\n",
    "    gc.collect() # Manual garbage collection needed since python may not clean up GPU resources automatically.\n",
    "    return(metrics)\n",
    "\n",
    "\n",
    "print('Starting xgboost '+run_type+' training....')\n",
    "xgb_model_name = 'python_telco_dask_xgb_'+run_type\n",
    "\n",
    "tic = time()\n",
    "training_metrics = dask_xgb_train_from_enc(client, run_type, enc_output_dir+'/train', label_col, xgb_params, xgb_model_name)\n",
    "t_dask_train = time() - tic\n",
    "\n",
    "training_metrics['total_time'] = t_dask_train\n",
    "print(training_metrics)\n",
    "print('Dask xgboost '+run_type+' training time:', '{:0.2f}'.format(t_dask_train) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load XGBOOST Model and Run Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference rounds....\n",
      "Scoring predictions in ./enc_data/train\n",
      "Scoring predictions in ./enc_data/test\n",
      "Inference against training data:  {'data_load_time': 0.05, 'predict_time': 5.05, 'score': {'auc': 0.9999648332595825, 'auc_time': 1.18}}\n",
      "Inference against (hold-out) test data:  {'data_load_time': 0.07, 'predict_time': 3.76, 'score': {'auc': 0.8218247294425964, 'auc_time': 0.01}}\n",
      "Total prediction time: 10.30s\n"
     ]
    }
   ],
   "source": [
    "def score_pred(run_type, y_true, y_pred, score_metric):\n",
    "    \"\"\"\n",
    "    Prediction scoring function.\n",
    "    \"\"\"\n",
    "    if run_type == 'gpu':\n",
    "#         import dask.dataframe as hw # Has internal switching for compatibility. Takes a long time to perform AUC score, but fast at prediction.\n",
    "        from cuml.metrics import roc_auc_score\n",
    "        from cuml.metrics.accuracy import accuracy_score\n",
    "        # TODO: inplace scoring to pair with inplace prediction? Only works with certain methods.\n",
    "    else:\n",
    "        # TODO: need parallelized roc_auc_score computation for auc.\n",
    "        from sklearn.metrics import roc_auc_score # Single-threaded?\n",
    "#         from sklearn.metrics import accuracy_score # Single-threaded\n",
    "        from dask_ml.metrics import accuracy_score # CPU parallelized\n",
    "\n",
    "    if score_metric == 'auc':\n",
    "        # AUC uses probabilities. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "        score_value = roc_auc_score(y_true, y_pred)\n",
    "    elif score_metric == 'acc':\n",
    "        # Accuracy score uses threshold value due to ==. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "        score_value = accuracy_score(y_true.round(), y_pred.round()) # y_pred needs to be converted explicitly. Dask doesn't know shape of y, y_pred if dask.dataframe.\n",
    "    return(score_value)\n",
    "    \n",
    "def dask_xgb_infer(client, run_type, data_path, label_col, score_metric='auc'):\n",
    "    \"\"\"\n",
    "    Use dask + xgboost for inferencing against already encoded data.\n",
    "    \"\"\"    \n",
    "    if run_type == 'gpu':\n",
    "        import dask_cudf as hw # Needed for xgb.dask.inplace_predict(). \n",
    "#         import dask.dataframe as hw # Has internal switching for compatibility. Takes a long time to perform AUC score, but fast at prediction.\n",
    "    else:\n",
    "        import dask.dataframe as hw\n",
    "    \n",
    "    model_file = 'python_telco_dask_xgb_'+run_type+'.model'\n",
    "    model = xgb.Booster(model_file=model_file)\n",
    "    \n",
    "    tic = time()\n",
    "    ddf_enc = hw.read_parquet(data_path).persist()\n",
    "\n",
    "    # Format data for xgboost:\n",
    "    feature_cols = [cc for cc in ddf_enc.columns if cc not in [label_col, 'cv_idx']]\n",
    "    X = ddf_enc[feature_cols].astype('float32')\n",
    "    y = ddf_enc[label_col].astype('float32')\n",
    "    \n",
    "#     # Persist data:\n",
    "#     X = client.persist(X)\n",
    "#     y = client.persist(y)\n",
    "#     wait([X, y])\n",
    "    data_load_time = np.round(time() - tic, 2)\n",
    "    \n",
    "    # Run predictions:\n",
    "    tic = time()\n",
    "    model.set_param('predictor', run_type + '_predictor')\n",
    "    model = client.scatter(model, broadcast=True)\n",
    "\n",
    "    # See https://xgboost.readthedocs.io/en/latest/tutorials/dask.html#running-prediction:\n",
    "#     y_pred = xgb.dask.predict(client, model, xgb.dask.DaskDMatrix(client, X, y)) # More efficient to avoid xgb.dask.DaskDMatrix()\n",
    "#     y_pred = xgb.dask.predict(client, model, X) # Use inplace_predict() can sometimes be faster.\n",
    "\n",
    "    # IMPORTANT: X.values required to get consistent CPU scoring. Issue with column ordering in dask.dataframe?\n",
    "#     y_pred = xgb.dask.inplace_predict(client, model, X.values) # Use inplace_predict() can sometimes be faster.\n",
    "    y_pred = xgb.dask.predict(client, model, X.values) # inplace_predict() doesn't work with xgb 1.4.0dev on rapids 21.06 build.\n",
    "\n",
    "    # Force computation of y's required for libraries without dask.dataframe support:\n",
    "    y_pred = y_pred.compute()\n",
    "    y = y.compute()\n",
    "    wait([y_pred, y])\n",
    "        \n",
    "    predict_time = np.round(time() - tic, 2)\n",
    "    \n",
    "    # Score predictions:\n",
    "    print('Scoring predictions in '+ data_path)\n",
    "    tic = time()\n",
    "    score_value = score_pred(run_type, y, y_pred, score_metric)\n",
    "    score_time = np.round(time() - tic, 2)\n",
    "\n",
    "    # TODO: have inference run distributively. Need roc_auc_score equivalent for dask-gpu. Maybe dask_cudf has it?\n",
    "    metrics = {\n",
    "        'data_load_time': data_load_time,\n",
    "        'predict_time': predict_time,\n",
    "        'score':\n",
    "            {score_metric: score_value,\n",
    "            score_metric+'_time': score_time\n",
    "                }\n",
    "        }\n",
    "    \n",
    "    del ddf_enc, X, y, y_pred, model\n",
    "    gc.collect()\n",
    "    return(metrics)\n",
    "\n",
    "\n",
    "print('Starting inference rounds....')\n",
    "tic = time()\n",
    "if test_size == 0:\n",
    "    inference_metrics_train = dask_xgb_infer(client, run_type, enc_output_dir+'/train', label_col, score_metric=score_metric)\n",
    "    inference_metrics_test = []\n",
    "else:\n",
    "    # Inference against entire data set in two steps:\n",
    "    inference_metrics_train = dask_xgb_infer(client, run_type, enc_output_dir+'/train', label_col, score_metric=score_metric)\n",
    "    inference_metrics_test = dask_xgb_infer(client, run_type, enc_output_dir+'/test', label_col, score_metric=score_metric)\n",
    "t_dask_infer = np.round(time() - tic, 2)\n",
    "\n",
    "end_time_str = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "print('Inference against training data: ', inference_metrics_train)\n",
    "print('Inference against (hold-out) test data: ', inference_metrics_test)\n",
    "print('Total prediction time:', '{:0.2f}'.format(t_dask_infer) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run GridSearchCV for Hyper-parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask cross-validation strategy: node\n",
      "Number of grid points: 12\n",
      "Total number of evaluations (with cross-validation): 96\n",
      "Best params: {'grid_idx': 2.0, 'num_boost_round': 49.0, 'train-auc-mean': 0.881754625, 'test-auc-mean': 0.842367625, 'mean_fold_train_time': 5.25625, 'max_depth': 4.0, 'eta': 0.1}\n",
      "Total grid search cv wall time: 212.77s\n"
     ]
    }
   ],
   "source": [
    "def get_grid_pt(grid_idx):\n",
    "    \"\"\"\n",
    "    Convert grid point to dict.\n",
    "    \"\"\"\n",
    "    # Update xgb_params:\n",
    "    xgb_params_ = xgb_params.copy()\n",
    "    cur_param = dict(gridsearch_df.iloc[grid_idx])\n",
    "    cur_param_start = cur_param.copy()\n",
    "    #     print('Running CV with: ', cur_param_start)\n",
    "\n",
    "    # Move num_boost_round out of dict:\n",
    "    if 'num_boost_round' in cur_param.keys():\n",
    "        n_rounds = int(cur_param['num_boost_round'])\n",
    "        cur_param.pop('num_boost_round')\n",
    "    else:\n",
    "        n_rounds = num_trees\n",
    "\n",
    "    # Some issues with dtype conversion when converting to dict?\n",
    "    try:\n",
    "        cur_param['max_depth'] = int(cur_param['max_depth'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    xgb_params_.update(cur_param)\n",
    "    return(xgb_params_)\n",
    "\n",
    "def assemble_ddmatrix(cv_train, cv_test, method=None):\n",
    "    \"\"\"\n",
    "    Assemble DMatrix for CPU/GPU.\n",
    "    \"\"\"\n",
    "    if method == 'dask':\n",
    "        if run_type == 'gpu':\n",
    "            # See example: https://github.com/dmlc/xgboost/blob/master/demo/dask/gpu_training.py\n",
    "            # `DaskDeviceQuantileDMatrix` is used instead of `DaskDMatrix`, be careful\n",
    "            # that it can not be used for anything else than training.\n",
    "            dcv_train = xgb.dask.DaskDeviceQuantileDMatrix(client, *cv_train)\n",
    "            dcv_test = xgb.dask.DaskDeviceQuantileDMatrix(client, *cv_test)\n",
    "        else:\n",
    "            dcv_train = DaskDMatrix(client, *cv_train)\n",
    "            dcv_test = DaskDMatrix(client, *cv_test)\n",
    "            \n",
    "    elif method=='local':\n",
    "        if run_type == 'gpu':\n",
    "            dcv_train = xgb.DeviceQuantileDMatrix(*cv_train)\n",
    "            dcv_test = xgb.DeviceQuantileDMatrix(*cv_test)\n",
    "        else:\n",
    "            dcv_train = xgb.DMatrix(*cv_train)\n",
    "            dcv_test = xgb.DMatrix(*cv_test)\n",
    "    else:\n",
    "        raise ValueError(\"Method not recognized. Select method in ['dask', 'local']\")\n",
    "    return(dcv_train, dcv_test)\n",
    "\n",
    "def xgb_cv_training_dask(xgb_params_cur, grid_idx, fold_idx, dcv_train, dcv_test):\n",
    "    \"\"\"\n",
    "    Use entire dask cluster each iteration for training. \n",
    "    \"\"\"\n",
    "    tic = time()\n",
    "    xgb_fold_model = xgb.dask.train(client, xgb_params_cur, dcv_train, num_boost_round=num_trees, \n",
    "                                    evals=[(dcv_train, 'train'), (dcv_test, 'test')], verbose_eval=False)\n",
    "    eval_history = xgb_fold_model['history']\n",
    "        \n",
    "    total_fold_train_time = np.round(time() - tic, 2)\n",
    "\n",
    "    boost_history = {}\n",
    "    for key, value in eval_history.items():\n",
    "        boost_history[key+'-'+score_metric] = value[score_metric]\n",
    "\n",
    "    boost_history = pd.DataFrame(boost_history).reset_index().rename(columns={'index': 'num_boost_round'})\n",
    "    boost_history['grid_idx'] = grid_idx\n",
    "    boost_history['fold_idx'] = fold_idx\n",
    "    boost_history['fold_train_time'] = total_fold_train_time\n",
    "    return(boost_history)\n",
    "\n",
    "\n",
    "def GridSearchCV_dask_sequential(client, train_data_loc):\n",
    "    \"\"\"\n",
    "    Sequential training of fully distributed dask xgboost model with grid search and cross-validation.\n",
    "    \"\"\"\n",
    "    from dask_ml.model_selection import KFold\n",
    "\n",
    "    if run_type == 'cpu':\n",
    "        import dask.dataframe as hw\n",
    "    elif run_type == 'gpu':\n",
    "        import dask_cudf as hw\n",
    "\n",
    "    df_enc_train = hw.read_parquet(train_data_loc).persist()\n",
    "    bool_cols = list(df_enc_train.select_dtypes(bool).columns)\n",
    "    df_enc_train[bool_cols] = df_enc_train[bool_cols].astype('int8') # DMatrix doesn't understand boolean\n",
    "    \n",
    "    cv_idx = df_enc_train['cv_idx'].to_dask_array(lengths=True)\n",
    "    feature_cols = [cc for cc in df_enc_train.columns if cc not in [label_col, 'cv_idx']]\n",
    "    X_train = df_enc_train[feature_cols].to_dask_array(lengths=True)\n",
    "    y_train = df_enc_train[label_col].to_dask_array(lengths=True)\n",
    "\n",
    "    # Grid search performed sequentially with each (fold_idx, grid_idx) using the entire dask cluster. \n",
    "    cv_results = []\n",
    "    tic = time()\n",
    "    iter_cnt = 0\n",
    "    for fold_idx in range(num_folds):\n",
    "        t_start = time()\n",
    "\n",
    "        # Slice X_train into KFolds for cross-validation.\n",
    "        Xii_train = X_train[cv_idx != fold_idx]\n",
    "        yii_train = y_train[cv_idx != fold_idx]\n",
    "\n",
    "        Xii_test = X_train[cv_idx == fold_idx]\n",
    "        yii_test = y_train[cv_idx == fold_idx]\n",
    "        \n",
    "        dcv_train, dcv_test = assemble_ddmatrix([Xii_train, yii_train], [Xii_test, yii_test], method='dask')\n",
    "        del Xii_train, yii_train, Xii_test, yii_test\n",
    "        gc.collect()\n",
    "        \n",
    "        for grid_idx in range(num_grid_pts):\n",
    "            xgb_params_cur = get_grid_pt(grid_idx)\n",
    "            cv_results.append(xgb_cv_training_dask(xgb_params_cur, grid_idx, fold_idx, dcv_train, dcv_test))\n",
    "            iter_cnt += 1\n",
    "            print('Completed cv'+str(fold_idx)+', grid_idx='+str(grid_idx)+\n",
    "                  '. Elapsed time within cv'+str(fold_idx)+': '+str(np.round(time()-t_start ,2))+'s.  ['+str(iter_cnt)+'/'+str(num_grid_pts*num_folds)+']')\n",
    "        \n",
    "        del dcv_train, dcv_test\n",
    "        gc.collect\n",
    "        \n",
    "    del df_enc_train, X_train, y_train\n",
    "    gc.collect()\n",
    "    return(pd.concat(cv_results))\n",
    "\n",
    "@dask.delayed\n",
    "def GridSearchCV_per_node(fold_idx, data_loc):\n",
    "    \"\"\"\n",
    "    Train single model per node. Make sure number of nodes is compatible with number of KFolds. \n",
    "    For example, 9-folds is compatible with [1,3,9] nodes and 8-fold compatible with [1,2,4,8], etc. \n",
    "    This reduces the impact of stragglers since each node operates on same amount of data and sweeps through all grid points.\n",
    "    \"\"\"\n",
    "    t_start = time()\n",
    "    if run_type == 'cpu':\n",
    "        import pandas as hw\n",
    "    elif run_type == 'gpu':\n",
    "        import cudf as hw\n",
    "\n",
    "    df_enc_train = hw.read_parquet(data_loc)\n",
    "    \n",
    "    if run_type == 'gpu':\n",
    "        bool_cols = list(df_enc_train.select_dtypes(bool).columns)\n",
    "        df_enc_train[bool_cols] = df_enc_train[bool_cols].astype('int8') # DMatrix doesn't understand boolean\n",
    "    else:\n",
    "        df_enc_train = df_enc_train.astype('float32')\n",
    "        \n",
    "    cv_idx = df_enc_train['cv_idx'].values\n",
    "    feature_cols = [cc for cc in df_enc_train.columns if cc not in [label_col, 'cv_idx']]\n",
    "    X_train = df_enc_train[feature_cols]\n",
    "    y_train = df_enc_train[label_col]\n",
    "\n",
    "    # Slice single fold and sweep across all grid points:\n",
    "    # Slice X_train into KFolds for cross-validation.\n",
    "    Xii_train = X_train[cv_idx != fold_idx]\n",
    "    yii_train = y_train[cv_idx != fold_idx]\n",
    "\n",
    "    Xii_test = X_train[cv_idx == fold_idx]\n",
    "    yii_test = y_train[cv_idx == fold_idx]\n",
    "\n",
    "    del df_enc_train, X_train, y_train\n",
    "    gc.collect()\n",
    "    \n",
    "#     dcv_train, dcv_test = assemble_ddmatrix([Xii_train, yii_train], [Xii_test, yii_test], method='local')\n",
    "    \n",
    "    # Need to construct dmatrix within function. Calling external function has issues with dask.delayed pickling.\n",
    "    if run_type == 'gpu':\n",
    "        dcv_train = xgb.DeviceQuantileDMatrix(Xii_train, yii_train)\n",
    "        dcv_test = xgb.DeviceQuantileDMatrix(Xii_test, yii_test)\n",
    "    else:\n",
    "        dcv_train = xgb.DMatrix(Xii_train, yii_train)\n",
    "        dcv_test = xgb.DMatrix(Xii_test, yii_test)\n",
    "\n",
    "    del Xii_train, yii_train, Xii_test, yii_test\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Loaded data and constructed DMatrix for cv'+str(fold_idx)+' in '+str(np.round(time()-t_start,2))+'s')\n",
    "    \n",
    "    cv_results = []\n",
    "    iter_cnt = 0\n",
    "    for grid_idx in range(num_grid_pts):\n",
    "        tic = time()\n",
    "        eval_history = {}\n",
    "        xgb_params_cur = get_grid_pt(grid_idx)\n",
    "        \n",
    "        # Dask delayed doesn't like having eval_history dict in separate function.\n",
    "        xgb_fold_model = xgb.train(xgb_params_cur, dcv_train, num_boost_round=num_trees, \n",
    "                                        evals=[(dcv_train, 'train'), (dcv_test, 'test')], evals_result=eval_history, verbose_eval=False)\n",
    "        iter_cnt += 1\n",
    "        print('Completed cv'+str(fold_idx)+', grid_idx='+str(grid_idx)+\n",
    "              '. Elapsed time within cv'+str(fold_idx)+': '+str(np.round(time()-t_start ,2))+'s.  ['+str(iter_cnt)+'/'+str(num_grid_pts)+']')\n",
    "        \n",
    "        \n",
    "        total_fold_train_time = np.round(time() - tic, 2)\n",
    "\n",
    "        boost_history = {}\n",
    "        for key, value in eval_history.items():\n",
    "            boost_history[key+'-'+score_metric] = value[score_metric]\n",
    "\n",
    "        boost_history = pd.DataFrame(boost_history).reset_index().rename(columns={'index': 'num_boost_round'})\n",
    "        boost_history['grid_idx'] = grid_idx\n",
    "        boost_history['fold_idx'] = fold_idx\n",
    "        boost_history['fold_train_time'] = total_fold_train_time\n",
    "        cv_results.append(boost_history)\n",
    "        \n",
    "    del dcv_train, dcv_test, xgb_fold_model\n",
    "    gc.collect()\n",
    "    return(pd.concat(cv_results))\n",
    "\n",
    "if enable_gridSearchCV == True:\n",
    "#     cv_strategy = 'node' # Select 'cluster' or 'node'. 'node' should have lower TCO if model can be trained in single node.\n",
    "    num_trees = 200 # Number of boosting rounds. Held constant without early stopping.\n",
    "    param_grid = {\n",
    "#         'max_depth': [2], # range() cannot be saved to JSON. Use explicit list.\n",
    "#         'eta': [0.1],\n",
    "        'max_depth': list(range(4, 11, 2)), # range() cannot be saved to JSON. Use explicit list.\n",
    "        'eta': [0.01, 0.05, 0.1] # eta==learning_rate\n",
    "    }\n",
    "    \n",
    "    param_names = list(param_grid.keys())\n",
    "    gridsearch_df = pd.DataFrame(list(itertools.product(*param_grid.values())), columns=param_names)\n",
    "    num_grid_pts = reduce(lambda x,y: x*y, [len(param_grid[key]) for key in param_grid.keys()])\n",
    "    \n",
    "    print('Dask cross-validation strategy:', cv_strategy)\n",
    "    print('Number of grid points:', str(num_grid_pts))\n",
    "    print('Total number of evaluations (with cross-validation):', num_grid_pts*num_folds)\n",
    "\n",
    "    tic = time()\n",
    "    if cv_strategy == 'cluster':\n",
    "        # Has issues when running multiple CV folds on dask. Mem not being released from dask.\n",
    "        gs_results = GridSearchCV_dask_sequential(client, enc_output_dir+'/train')\n",
    "    elif cv_strategy == 'node':\n",
    "        gs_results_delayed = [GridSearchCV_per_node(fold_idx, enc_output_dir+'/train') for fold_idx in range(num_folds)]\n",
    "#         progress(gs_results_delayed) # Show progress in CLI. Won't be in notebook unless last line of cell. Blocking until complete.\n",
    "        gs_results = pd.concat(dask.compute(gs_results_delayed, scheduler=client)[0])\n",
    "    \n",
    "    t_gridSearchCV = np.round(time() - tic, 2)\n",
    "    \n",
    "    # Compute mean score per fold:\n",
    "    gscv_tbl = (gs_results\n",
    "                     .groupby(['grid_idx', 'num_boost_round'])\n",
    "                     .mean()\n",
    "                    ).drop(columns=['fold_idx']).rename(columns={\n",
    "        'fold_train_time': 'mean_fold_train_time', \n",
    "        'train-'+score_metric: 'train-'+score_metric+'-mean', 'test-'+score_metric: 'test-'+score_metric+'-mean'})\n",
    "\n",
    "    gscv_tbl = gscv_tbl.merge(gridsearch_df, left_on='grid_idx', right_index=True, how='left').reset_index()\n",
    "    \n",
    "    # Get best round within each grid point:\n",
    "    ref_score_col = 'test-'+score_metric+'-mean'\n",
    "    best_idx = gscv_tbl[ref_score_col].argmax()\n",
    "    best_params_ = dict(gscv_tbl.iloc[best_idx])\n",
    "    print('Best params:', best_params_)\n",
    "    \n",
    "    # Pick best score within each run_id, then use mean_fit_time to determine if model is desirable.\n",
    "    # .idxmax() returns first occurence of maxima.\n",
    "    best_idx_per_group = gscv_tbl.groupby('grid_idx')[ref_score_col].idxmax()\n",
    "    gscv_tbl_sm = gscv_tbl.iloc[best_idx_per_group].sort_values(ref_score_col, ascending=False)\n",
    "    \n",
    "    print('Total grid search cv wall time: '+str(t_gridSearchCV) + 's')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Dask xgboost gpu training time: 10.78s\n",
      "Total prediction time: 10.30s\n",
      "Grid search time: 212.77s\n"
     ]
    }
   ],
   "source": [
    "# Record important variables/metrics to JSON output:\n",
    "output_dict = {}\n",
    "\n",
    "output_dict['cluster_type'] = cluster_type\n",
    "output_dict['run_type'] = run_type\n",
    "output_dict['data_format'] = data_format\n",
    "output_dict['test_size'] = test_size\n",
    "output_dict['enc_num_row_groups'] = enc_num_row_groups\n",
    "output_dict['storage_backend'] = storage_backend\n",
    "output_dict['t_encode'] = np.round(t_encode, 2)\n",
    "output_dict['t_train'] = np.round(t_dask_train, 2)\n",
    "output_dict['t_infer'] = np.round(t_dask_infer, 2)\n",
    "output_dict['training_metrics'] = training_metrics\n",
    "output_dict['inference_metrics_train'] = inference_metrics_train\n",
    "output_dict['inference_metrics_test'] = inference_metrics_test\n",
    "\n",
    "if enable_gridSearchCV == True:\n",
    "    output_dict['t_gridSearchCV'] = t_gridSearchCV\n",
    "#     output_dict['best_model_hold_out_test_score'] = best_model_hold_out_test_score\n",
    "    output_dict['gridSearchCV_results'] = {\n",
    "        'num_trees': num_trees,\n",
    "        'param_grid': str(param_grid),\n",
    "#         'cv_results_': str(gs_results.cv_results_),\n",
    "#         'best_params_': str(gs_results.best_params_),\n",
    "#         'best_score_': gs_results.best_score_,\n",
    "#         'best_estimator_': str(gs_results.best_estimator_)\n",
    "        'best_params_': str(best_params_),\n",
    "        'best_score_by_group_': gscv_tbl_sm.to_json(), \n",
    "        'cv_results_': gscv_tbl.to_json(),   \n",
    "    }\n",
    "    \n",
    "\n",
    "# if run_type == 'gpu':\n",
    "#     output_dict['fil_metrics'] = fil_metrics\n",
    "\n",
    "output_dict['xgb_params'] = xgb_params\n",
    "\n",
    "# Load xgb model output json and insert into metrics file:\n",
    "with open('/tmp/'+xgb_model_name+'.json') as json_file:\n",
    "    xgb_model_json = json.load(json_file)\n",
    "\n",
    "output_dict['xgb_save_model'] = xgb_model_json\n",
    "\n",
    "output_dict['start_time'] = start_time_str\n",
    "output_dict['end_time'] = end_time_str\n",
    "\n",
    "\n",
    "# TODO: write metrics file to hdfs?\n",
    "\n",
    "# Output ML log files:\n",
    "if not os.path.exists('ml_logs'):\n",
    "    os.makedirs('ml_logs')\n",
    "\n",
    "with open('ml_logs/'+run_type+'_'+re.sub('[/: ]', '', start_time_str)+'.json', 'w') as json_file:\n",
    "    json.dump(output_dict, json_file)\n",
    "    \n",
    "print('****************************')    \n",
    "print('Dask xgboost '+run_type+' training time:', '{:0.2f}'.format(t_dask_train) + 's')\n",
    "print('Total prediction time:', '{:0.2f}'.format(t_dask_infer) + 's')\n",
    "\n",
    "if enable_gridSearchCV == True:\n",
    "    print('Grid search time:', str(t_gridSearchCV) + 's')\n",
    "\n",
    "# client.close()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "xgboost-telco-data-standalone",
   "notebookOrigID": 3943293,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
